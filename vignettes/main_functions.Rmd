---
title: "Main Functions"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{eatPrep}
  %\VignetteEncoding{UTF-8}
  %\VignetteEngine{knitr::rmarkdown}
editor_options: 
  chunk_output_type: console
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup, include=FALSE}
library(knitr)
```

## Introduction

#### Installation

You can install the package using the following line of code:

```{r installing and loading, warning=FALSE, message=FALSE}
#remotes::install_github("https://github.com/sachseka/eatPrep")
library(eatPrep)
```

#### Outline

In this vignette we explain how to use the package's main functions. Main functions are functions that are part of the minimal workflow of data preparation for IRT analyses using item meta data, that is, performing checks, merging, recoding, aggregating and scoring variables. For explanation of further important functions and diagnostic tools for data preparation and plausibility checks, there will be another vignette. 

You can click on the specific function to jump to its explanation.

```{r outline functions, echo=FALSE}
head1 <- c("**Reading in (Meta) Data**", "")
head2 <- c("**Checks**", "")
head3 <- c("**Merging, Recoding, Aggregating, Scoring**", "")
head4 <- c("**Wrapper**", "")
head5 <- c("**Export**", "")
# 1
read1 <- c("[readDaemonXlsx()](#items-via-zkdaemon)", "read in the inputlist that was created using the EDV-tool 'ZKDaemon'.")
read2 <- c("[readSpss()](#spss-data)", "read in SPSS files.")
read3 <- c("[readMerkmalXlsx()](#merkmalsauszug)", "read in additional item and exercise attributes like processing time, formats, content categories, ...")
# 2
check1 <- c("[checkInputList()](#checking-data)", "check the inputList for internal consistency.")
check2 <- c("[checkData()](#checkdata)", "check data sets according to item meta information and other plausibility checks of the data.")
check3 <- c("[checkDesign()](#checkdesign)", "check data sets according to test design meta information.")
# 3
merge1 <- c("[mergeData()](#merging-data)", "merging the data sets and diagnostics to ensure a fit.")
recode1 <- c("[recodeData()](#recoding-data)", "recode the subitems according to meta information from the inputList.")
aggregate1 <- c("[aggregateData()](#aggregating-data)", "aggregate subitems into items.")
score1 <- c("[scoreData()](#scoring-data)", "recode items that previously consisted out of subitems.")
score2 <- c("[mnrCoding()](#mnrcoding)", "recoding the last items (if empty) in each block (see test design) as 'missing not reached'.")
# 4
wrap1 <- c("[automateDataPreparation()](#wrapper)", "wraps most of the other features into one big function.")
# 5
export1 <- c("[collapseMissings()](#collapsing-data)", "recodes the missing types into predefined scores (usually 0.1, NA). Such a “collapster” R-data.frame can be passed directly to eatModel for scaling.")
export2 <- c("[writeSpss()](#export-spss)", "produces an SPSS syntax and a .txt data set that can be read into SPSS with the syntax including all meta data.")
export3 <- c("[prep2GADS()](#prepare-for-eatgads)", "both the raw data sets and the finished, scored data sets, including all their meta data, can be exported into a GADSdat object for data storage or further processing in eatGADS.")

outline <- rbind.data.frame(head1, read1, read2, read3,
                            head2, check1, check2, check3,
                            head3, merge1, recode1, aggregate1, score1, score2,
                            head4, wrap1,
                            head5, export1, export2, export3)
names(outline) <- c("Function", "Explanation")
kable(outline, caption = "**Functions Overview**")
```


#### Data Structure

In the [Getting Started Vignette](./vignettes/getting_started.Rmd) we saw what we use the `eatPrep` package for and how the data structure looks like. Now, we will look at the main functions to learn how to implement that via R.

As a reminder, an `eatPrep` data set contains the following layers: 

|||
|-|-|
|**booklets** |containing blocks|
|**blocks**| containing units (= items)| 
| **units**| containing subunits/subitems|
| **subunits**| having values and|
| **values**| including missings and recode values|

And here is an overview for different value types the IQB uses: 

```{r missing-types, echo=FALSE}
mir98 <- c(-98, "mir", "missing invalid response",
           "(1) Item was edited, and (2a) empty answer or (2b) invalid (joke) answer.")
mbo99 <- c(-99, "mbo", "missing by omission",
           "Item wasn't edited but seen, or wasn't seen, but there are seen or edited subsequent Items.")
mnr96 <- c(-96, "mnr", "missing not reached",
           "(1) Item wasn't seen, and (2) all subsequent Items weren't seen, either.")
mci97 <- c(-97, "mci", "missing coding impossible",
           "(1) Item should/could have been edited, and (2) answer can't be analysed due to technical problems.")
mbd94 <- c(-94, "mbd", "missing by design",
           "no answer, because Item wasn't shown to the testperson by design.")
Mtypes <- rbind.data.frame(mir98, mbo99, mnr96, mci97, mbd94)
names(Mtypes) <- c("Code", "Label", "Abbr", "Explanation")

kable(Mtypes, caption = "**Missing Types**")
```


## Input

`inputMinimal` contains the bare minimum for all functions in `eatPrep` to work, `inputList` contains additional metadata about the items (such as information about the task's content). 

For more Information on how the different layers or `Input Tables` look like, please see the [Getting Started Vignette](./vignettes/getting_started.Rmd).

```{r tempsetup}
inputMinimal <- list(units = inputList$units[ -nrow(inputList$units), c("unit", "unitAggregateRule")],
                     subunits = inputList$subunits[, c("unit", "subunit","subunitRecoded")],
                     values = inputList$values[ , c("subunit", "value", "valueRecode", "valueType")],
                     unitRecodings = inputList$unitRecodings[ , c("unit", "value", "valueRecode", "valueType")],
                     blocks = inputList$blocks,
                     booklets = inputList$booklets,
                     rotation = inputList$rotation)
```

## Input Data

We have several overlapping booklets with several blocks in each booklet. Moreover, there is a unique identifier for each person and some additional information about each student like their gender or their socioeconomic status. There is one data set per booklet. In order to prepare the data, we need to construct one large data set.

In order to do that we first need to read the data into R, check the data for invalid or or incorrect codes and then merge the data into one data set. In the following the different functions to do that are described. `inputDat` gives us a first idea on how the data is supposed to look like. 

```{r inputDat}
# looking at the data
str(inputDat)
```

### Reading in (Meta) Data

First, we need to get the information from our IQB data bank via ZKDaemon, or alternatively via SPSS. 

#### Items via ZKDaemon

ZKDaemon is a program used by IQB that can be found in the IQB internal folders (i:). After installing you can get the meta data and the items from your specific study using information stored in the IQB Databases (DB2/DB3/DB4). Alternatively you can get the meta data from an SPSS file via ZKDaemon. Within the program you can set missing types and import a test design. Then you can produce Excel files, which are expected to have the following sheets: “units”, “subunits”, “values”, “unitrecoding”, “sav-files”, “params”, “aggregate-missings”, “itemproperties”, “propertylabels”, “booklets”, and “blocks”. 

The function `readDaemonXlsx()` reads the Excel file into R and will produce a warning if any sheets are missing. It needs one character string (filename) containing path, name and extension of the Excel file (.xlsx) produced by ZKDaemon. 

The function returns a list of data frames containing information that is required by the data preparation functions. `inputList` shows an example of this list.

```{r readDeamonXlsx}
filename <- system.file("extdata", "inputList.xlsx", package = "eatPrep")
readDaemon <- readDaemonXlsx(filename)
str(readDaemon)
```

#### SPSS Data

To get the input from SPSS data files, `readSpss()` reads the data into R and converts all variables to the class `character`. The function needs the name of the SPSS data file and has the option to specify some more attributes. For more information use the help function `?readSpss`. 

```{r readSpss example}
#readSpss("./inst/extdata/booklet1.sav")
#readSpss("./inst/extdata/booklet1.sav")
#readSpss("./inst/extdata/booklet1.sav")
```

#### Merkmalsauszug

The software "IQB Item-DB" produces Excel files named "Merkmalsauszug" using information stored in the IQB Databases. The file is expected to have the sheets: “Itemmerkmale”, “Aufgabenmerkmale”. The order doesn't matter. The file contains information about the attributes of the items and exercises. 

The function `readMerkmalXlsx()` read the Excel file into R and will produce a warning if any sheets are missing or wrongly specified. It needs one character string (filename) containing path, name and extension of the Excel file (.xlsx) produced by IQB Item-DB. Per default the Item-ID is created without converting numbers to lowercase letters (`tolcl`) and a merged data frame contaning both "Itemmerkmale" and "Aufgabenmerkmale" will be created (`alleM`).

The function returns a list of data frames containing Itemmerkmale, Aufgabenmerkmale and AlleMerkmale (optional).

```{r readMerkmalXlsx}
filename <- system.file("extdata", "itemmerkmale.xlsx", package = "eatPrep")
readMerkmalXlsx(filename, tolcl = FALSE, alleM = TRUE)
```


## Checks

After reading in all the data, we need to check, whether it is in the right format and all codes and missing codes were assigned correctly. 

#### checkInputList

`checkInputList` checks whether the object `inputList` has the required form. It has two arguments: the `inputList` and `mistypes`, for which it will be checked, whether the missing types in this vector are defined for all items.

```{r checkInputList, eval=FALSE}
data(inputList)
checkInputList(inputList)
```

The xlsx-file produced by 'ZKDaemon' is expected to have the following sheets: “units”, “subunits”, “values”, “unitrecoding”, “sav-files”, “params”, “aggregate-missings”, “itemproperties”, “propertylabels”, “booklets”, and “blocks”. `readDaemonXlsx` will produce a warning if any sheets are missing or wrongly specified. `checkInputList` performs many additional checks to this.

#### checkData

`checkData()` checks data frames for missing or duplicated entries in the ID variable, persons and/or variables without valid codes, and generally invalid codes. The results of that check will be written in the console. 

The function needs a data frame to be checked (`dat`) and its name (`datnam`), especially if there are multpile data frames (e.g. a list of data frames). Furthermore it needs data frames with code, subunit and unit information (`values`, `subunits` and `units`), and a string for an ID column name (ID). You can turn of printing information to the console with `verbose`. 

```{r checkData, eval=FALSE}
checkData(dat, datnam, values, subunits, units, ID = NULL, verbose = TRUE)
```

Examples of data frames for `values`, `subunits` and `units` can be found by typing `inputList` in the console.

#### checkDesign

`checkDesign()` checks whether a data frame corresponds to a particular rotated block design, i.e. whether all persons have valid codes on all items they were presented with and one consistent missing code for all items they were not presented with.

The function also needs a data frame to be checked (`dat`), as well as data frames containing information on the number and column names of blocks in each booklet (`booklets`), on the names of subunits and their order within each block (`blocks`) and about which participant worked on which booklet (`rotation`). `sysMis` specifies the missing code for items that were not administered to a participant and `id` indicates the name of the participant identifier variable in `dat`. This is needed, when you perform `checkDesign()` on a data frame that is the result of `recodeData()` which renames `subunits` according to `subunitRecoded` in `subunits` sheet.

`subunits` is an optional argument to identify the names of recoded subunits. And you can turn off printing information with `verbose`. 

```{r checkDesign, eval=FALSE}
checkDesign(dat, booklets, blocks, rotation, sysMis="NA", id="ID", subunits = NULL, verbose = TRUE)
```

`inputDat` and `inputList` are examples on how these data frames are supposed to look like. When you copy and paste the following code in your console, you can look at the data frames. 

```{r checkDesign examples, eval=FALSE}
data(inputDat)
data(inputList)
```

## Merging, Recoding, Aggregating, Scoring

### Merging Data

Now that we checked that the data frames meet our requirements, we can merge a list of data frames into a single data frame by using `mergeData()`. For that we need a list of data frames, like `inputDat` which contains data of three booklets. The function returns a data frame containing unique cases and unique variables. All cases and all variables from the original data sets will be kept and matched.

`mergeData()` provides detailed diagnostics about value mismatches. If two identically named columns in two data sets do not have identical values, NAs are replaced by valid codes stemming from the other data set(s) and if two different valid values are found, the first value will be kept and the other dropped, and the user will be informed about the mismatch. Additionally, `NA` resulting from the merge (e.g., in repeated block designs) can be replaced with a customed character missing to facilitate future data preparation of the merged data set. See Table "Missing Types" for standard missing types for other functions in the `eatPrep` package.

When merging data frames with this function you need to specify at least two arguments: `newID` and `datList`. `newID` has to be a character vector length one indicating the name of the identifier variable (ID) in the merged data set and/or the name of the ID in every data frame in `datList`, if not specified differently in `oldIDs`. `datList` is the list of data frames to be merged, e.g. `inputDat`. 

```{r mergeData1}
mergedDataset <- mergeData(newID = "ID", datList = inputDat)
str(mergedDataset)
```

Furthermore, you can specify some more arguments, but they have default options, so you don't need to. Here is an example where the IDs are changed via `oldIDs` and where NAs are replaced by "mbd" (missing by design). For more information use the help function `?mergeData`.

```{r mergeData2}
mergedDataset2 <- mergeData(newID = "idstud", datList = inputDat, oldIDs = c("ID", "ID", "ID"), addMbd = TRUE)
str(mergedDataset2)
```


### Recoding Data

After importing the data and making sure it has the right format, the next step is to adjust the missing values. 

First, you recode data sets with several kinds of missings values. For that, you need recode data sets with special consideration of missing values. See `collapseMissings()` for supported types of missing values. `recodeData()` recodes the specified data frames and will give warnings, if missing or incomplete recode information is found. Values without recode information will not be recoded. 

Examples of data frames `values` and `subunits` can be found when copy-pasting the following code in you console: 

```{r exmaple recode data frames, eval=FALSE}
inputList$values
inputList$subunits
```

`recodeData()` uses the recode information from those two data frames and recodes the variables on `dat` accordingly. The columns will be named according to the specifications in `subunits$subunitRecoded`, if `subunits` is not provided, item names will not be changed for recoded items. 

```{r recodeData}
datRec <- recodeData(dat = inputDat[[1]], values = inputList$values, subunits = inputList$subunits, verbose = TRUE)
str(datRec)
```

### Aggregating Data

After recoding missing values, the subunits are combined one by one via `aggregateData()`.

This function needs three data frames: one containing the data to be aggregated (`dat`), one containing the subunit information (`subunits`), and one containing the unit information (`units`). 

Optionally, you can specify how missing values should be aggregated (`aggregatemissings`) like in the example, or which column names the returned data frame should have (`recodedData`), for instance. Type `?aggregateData` into your console to learn more. 

```{r aggregateData prep aggregatemissings example}
am <- matrix(c(
  "vc" , "mvi", "vc" , "mci", "err", "vc" , "mbi", "err",
  "mvi", "mvi", "err", "mci", "err", "err", "err", "err",
  "vc" , "err", "mnr", "mci", "err", "mir", "mnr", "err",
  "mci", "mci", "mci", "mci", "err", "mci", "mci", "err",
  "err", "err", "err", "err", "mbd", "err", "err", "err",
  "vc" , "err", "mir", "mci", "err", "mir", "mir", "err",
  "mbi", "err", "mnr", "mci", "err", "mir", "mbi", "err",
  "err", "err", "err", "err", "err", "err", "err", "err" ),
  nrow = 8, ncol = 8, byrow = TRUE)

dimnames(am) <-
  list(c("vc" ,"mvi", "mnr", "mci",  "mbd", "mir", "mbi", "err"),
       c("vc" ,"mvi", "mnr", "mci",  "mbd", "mir", "mbi", "err"))
```

```{r aggregateData example}
# using datRec from the chapter "recodeData()"
datAggr <- aggregateData(datRec, inputList$subunits, inputList$units,
    aggregatemissings = am, rename = TRUE, recodedData = TRUE,
    suppressErr = TRUE, recodeErr = "mci", verbose = TRUE)
```

### Scoring Data

The next step is to score data set with special consideration of missing values. The function `scoreData()` is very similar to `recodeData()`, but with a few defaults that are better suited for scoring. `scoreData()` will give warnings when incomplete scoring information is found. Values without scoring information will not be scored.

Again, you need to specify three data frames. One data frame that you get after completing the steps you did so far or by using `automateDataPreparation` (`dat`), one with information about the scoring of units (`unitrecodings`), and one with subunit information (`subunits`). Examples for the last two data frames can be found via `inputList`.

```{r automateDataPreparation for scoreData, message=FALSE}
prepDat <- automateDataPreparation (inputList = inputList, datList = inputDat,
    readSpss = FALSE, checkData=FALSE, mergeData = TRUE, recodeData=TRUE,
    aggregateData=TRUE, scoreData= FALSE, writeSpss=FALSE, verbose = TRUE)
```

```{r scoreData example}
datSco <- scoreData(prepDat, inputList$unitRecodings, inputList$subunits,
    verbose = TRUE)
```

#### mnrCoding

Then you can convert missing responses coded as "missing by intention" (`mbi`) at the end of a block of items to "missing not reached" (`mnr`) via `mnrCoding()`. The function returns a data frame with "missing not reached" coded as `mnr`. For each person with at least one `mnr` in the returned data set the names of recoded variables are given as an attribute to `dat`.  

For that to work you need to specify the following arguments, as they don't have any default settings:

|Argument|Explanation|
|-|-|
|**dat** |A data set. Missing by intention needs to be coded `mbi`|
|**pid**| Name or column number of the identifier (ID) variable in `dat`| 
| **rotation.id**| A character vector of length 1 indicating the column name of the test booklet identifier in `dat`|
| **blocks**| A data frame containing the sequence of subunits in each block in long format. The column names need to be `subunit`, `block`, `subunitBlockPosition`|
| **booklets**| A data frame containing the sequence of blocks in each booklet in wide format. The column names need to be `booklet`, `block1`, `block2`, `block3`, ...|
| **breaks**| Number of blocks after which `mbi` shall be recoded to `mnr`, e.g., `c(1,2)` to specify breaks after the first and second block|

There are more arguments with default values which to you can specify, but don't have to. 

`nMbi`, for instance, specifies the number of subunits at the end of a block that need to be coded `mbi`. The default is 2, i.e. if the last and second to last subitem in a block are coded `mbi`, both subunits, as well as the preceding subunits coded `mbi`, will be recoded to `mnr`. If `nMbi` is larger than the number of subunits in a given block, no subitem in this block will be recoded. If all subunits in a block are coded `mbi`, none of them will be recoded to `mnr`. ``nMbi` needs to be > 0. 

`subunits` has the default `NULL`, but when you specify a data frame, `recodeMbiToMnr` expects to find the recoded subunits in `dat`.

Examples for the data frames `booklets`, `blocks`, `rotation` and `subunits` can be found via `inputList`. Here is an example use case of `mnrCoding()`. The first two functions (`automateDataPretatration()` and `mergeData()`) create the data frame `dat` for `mnrCoding()`. 

```{r mnrCoding setup, message=FALSE}
prepDat <- automateDataPreparation(inputList = inputList, 
    datList = inputDat, readSpss = FALSE, checkData=FALSE, 
    mergeData = TRUE, recodeData=TRUE, aggregateData=FALSE, 
    scoreData= FALSE, writeSpss=FALSE, verbose = TRUE)
prepDat2 <- mergeData("ID", list(prepDat, inputList$rotation))
```

```{r mnrCoding example}
mnrDat <- mnrCoding(dat = prepDat2, pid = "ID", 
    booklets = inputList$booklets, blocks = inputList$blocks, 
    rotation.id = "booklet", breaks = c(1, 2), 
    subunits = inputList$subunits, nMbi = 2, mbiCode = "mbi", 
    mnrCode = "mnr", invalidCodes = c("mbd", "mir", "mci"), 
    verbose = TRUE)
```

Type `?mnrCoding` into your console to learn more. 

## Wrapper

Instead of using all the individual functions as described above, you can also use the wrapper function `automateDataPreparation`, which contains most of the described functions. Here is an overview over the arguments that call the corresponding function.

```{r wrapper overview, echo=FALSE}
readspss <- c("`readSpss`", "readSpss()")
checkdata <- c("`checkData`", "checkData()")
mergedata <- c("`mergeData`", "mergeData()")
recodedata <- c("`recodeData`", "recodeData()")
recodemnr <- c("`recodemnr`", "mnrCoding()")
aggregatedata <- c("`aggregateData`", "aggregateData()")
scoredata <- c("`scoreData`", "scoreData()")
collapsemissings <- c("`collapseMissings`", "collapseMissings()")
writespss <- c("`writeSpss`", "writeSpss()")

wrap <- rbind.data.frame(readspss, checkdata, mergedata, recodedata, recodemnr,
                         aggregatedata, scoredata, collapsemissings, writespss)
names(wrap) <- c("Argument", "Corresponding Function")
kable(wrap)
```

But there are many more arguments that may need to consider. For more information see `?automateDataPreraration`. 

Here is an example use case and its output. `automateDataPreparation` returns a data frame resulting from the final data preparation step.

```{r wrapper example}
data(inputList)
data(inputDat)
preparedData <- automateDataPreparation(inputList = inputList,
    datList = inputDat,  path = getwd(),
    readSpss = FALSE, checkData = TRUE,  mergeData = TRUE,
    recodeData = TRUE, recodeMnr = TRUE, breaks = c(1,2),
    aggregateData = TRUE, scoreData = TRUE,
    writeSpss = FALSE, verbose = TRUE)
```


## Export

After the data preparation is done, you can prepare the data sets for exporting to then use them in the packages `eatModel` and `eatGADS`.

### Collapsing Data

The last step is to recode character missings to numerical types with `collapseMissings()`, usually to 1,0 or NA, but other values are also possible . All variables need to be converted to `numeric`, as well, so you can pass the data set to `eatModel` afterwards. 

You can use the data frame that is returned by `recodeData`, which we called `datRec` earlier (`dat`). But its main purpose is to finish  the scored data set as it comes out of `scoreData` or `automateDataPreparation`.

`missing.rule` is a list containing information which character missings should be converted to `0`or `NA`. It has default settings, but you can adapt them if needed. Type `?collapseMissings` into your console to learn more. 

```{r collapseMissings example}
datColMis <- collapseMissings(datRec)
```

After doing that you should have a data frame that you can now use for further processing with the `eatModel` package.

### Export SPSS

With `writeSpss` you can create a .txt file and a SPSS syntax file, which can then be used in SPSS. You need the four data frames `dat`, `values`, `subunits` and `units`, the last three are usually part of the `inputList`. You also need to specify the file's names and where to save those new files to.

The function creates and saves those files, but the actual return values for this function is `NULL`.

```{r writeSpss example, eval=FALSE}
writeSpss(dat, values, subunits, units,
    filedat = "mydata.txt", filesps = "readmydata.sps",
    missing.rule = list(mvi = 0, mnr = 0, mci = NA, mbd = NA, mir = 0, mbi = 0),
    path = getwd(), sep = "\t", dec = ",", verbose = FALSE)
```


### Prepare for eatGADS

`prep2GADS` converts the data frame that we prepared to an eatGADS object for further use in the package `eatGADS`. It uses the meta data stored in `inputList`, so it needs the `inputList` as an argument, as well as our data frame `dat`, that we have been preparing.

Here you can see two examples for creating eatGADS objects. The first example exports scored data (`trafoType` = "scored"), which usually has 0/1 values and mistypes like mbi/mbo etc. The second example exports the raw data (`trafoType` = "raw"), including the original values and subunits. 

```{r prep2GADS prep, message=FALSE}
data(inputDat)
data(inputList)

# for GADSobj1
prepDatScored <- automateDataPreparation(inputList = inputList, datList = inputDat,
    readSpss = FALSE, checkData=FALSE, mergeData = TRUE, recodeData=TRUE,
    aggregateData=TRUE, scoreData=TRUE, writeSpss=FALSE, verbose = TRUE)

# for GADSobj2
prepDatRaw <- automateDataPreparation(inputList = inputList, datList = inputDat,
                                      readSpss = FALSE, checkData=FALSE, mergeData = TRUE, 
                                      recodeData=FALSE, aggregateData=FALSE, scoreData=FALSE, 
                                      writeSpss=FALSE, verbose = TRUE)
```


```{r prep2GADS example}
GADSobj1 <- prep2GADS(dat = prepDatScored, inputList = inputList[1:3], trafoType = "scored",
                      verbose=TRUE)

GADSobj2 <- prep2GADS(dat = prepDatRaw, inputList = inputList[1:3], trafoType = "raw", 
                      verbose=TRUE)
```


